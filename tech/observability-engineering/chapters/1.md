# Chapter 1 - What is Observability?

## Mathematical Definition of Observability

The term "observability" was coined by RudolfE. Kálmán in his 1960 paper to describe mathematical control systems. In control theory, **observability** is defined as a measure of how well internal states of a system can be inferred from knowledge of its external outputs.

## Applying Observability to Software Systems

For a software application to have **observability**, you must be able to do the following:

- Understand the inner workings of your application
- Understand any system state your application may have gotten itself into, even new ones that have not been seen before
- Understand the inner workings and system state solely by observing and interrogating external tools
- Understand the internal state without shipping any _new_ custom code to handle it -> that implies you needed prior knowledge to explain it

If you can understand any bizarre or novel state _without shipping new code_, then you have **observability**.

**Observability** is not a synonym for telemetry and not some suite of tools a SAAS can provide. It is requires evolving the way we think about gathering the data needed to debug effectively.

## Why Observability Matters Now?

Monitoring does not equal observability. 

## Why Are Metrics and Monitoring Not Enough?

A _metric_ is a single number, with tags optionally appended for grouping and searching. They are cheap, have a predictable storage footprint, and are easy to aggregate into time-series. This is good to a limit, but when you need to answer more specific questions, developers tend to fallback to more lower level tools or `print` statements.

The sheer number of possible states the system could get itself into will outstrip your teams ability to pattern-match based on prior outages.

Monitoring and metrics-based tools were build with certain assumptions about the architecture and organizations that served in-practice as a cap on complexity. In practice, many of these assumptions are not true in production.

## Debugging with Metrics Versus Observability

Given today's systems and how complex they are, it is near impossible to hold in one's head the a mental model for the application - especially an up to date one.

Metrics-based approaches are great when you have hit that known failure mode before. They struggle to help when an outage is happening in the moment. 

In modern cloud native systems, the hardest thing about debugging is no longer understanding how the code runs but finding _where in your system_ the code with problem lives.

Debugging with metrics requires you to connect dozens of disconnected metrics that were recorded overt the course of executing any one particular request, across any number of services or machines, to infer what might have occurred over the various hops need for its fulfillment.

Debugging with **observability** starts with a very different substrateL a deep context of what was happening when this action occurred.

## The Role of Cardinality

Cardinality matters for observability, because _high-cardinality information is almost always the most useful_ in identifying data for debugging or understanding a system.

Metrics based systems only deal with low-cardinality data at any reasonable scale.

When debugging with metrics, you have to decide - _in advance_ what information you might need to diagnose that bug. This is impossible given the near infinite problem space of potential failures.

## The Role of Dimensionality

Cardinality refers to the _uniqueness_ of data, dimensionality refers to the number of keys withing data. Highly dimensional data allows for more context to be capture at that event.